#面试 #主动学习 

- [[#一、动机篇|一、动机篇]]
		- [[#1.1 主动学习是什么？|1.1 主动学习是什么？]]
		- [[#1.2 为什么需要主动学习？|1.2 为什么需要主动学习？]]
- [[#二、主动学习篇|二、主动学习篇]]
		- [[#2.1 主动学习的思路是什么？|2.1 主动学习的思路是什么？]]
		- [[#2.2 主动学习方法 的价值点在哪里？|2.2 主动学习方法 的价值点在哪里？]]
- [[#三、样本选取策略篇|三、样本选取策略篇]]
		- [[#3.1 以未标记样本的获取方式的差别进行划分|3.1 以未标记样本的获取方式的差别进行划分]]
		- [[#3.2 测试集内选取“信息”量最大的数据标记|3.2 测试集内选取“信息”量最大的数据标记]]
			- [[#3.2 测试集内选取“信息”量最大的数据标记#3.2.1 测试集内选取“信息”量最大的数据标记|3.2.1 测试集内选取“信息”量最大的数据标记]]
			- [[#3.2 测试集内选取“信息”量最大的数据标记#3.2.2 依赖不确定度的样本选取策略（Uncertainty Sampling, US）|3.2.2 依赖不确定度的样本选取策略（Uncertainty Sampling, US）]]
			- [[#3.2 测试集内选取“信息”量最大的数据标记#3.2.3 基于委员会查询的方法（Query-By-Committee，QBC）|3.2.3 基于委员会查询的方法（Query-By-Committee，QBC）]]

### 一、动机篇
##### 1.1 主动学习是什么？
主动学习是一种机器学习的方法，它试图减少需要标记的数据量，同时提高模型的性能。在主动学习中，模型会自动选择最有益的样本来进行标记，以便在每次迭代中最大限度地提高模型的性能。这种方法通常用于监督学习任务，特别是在标记数据非常昂贵或困难获取的情况下。

主动学习的基本思想是在训练过程中，模型会选择一些未标记的样本，然后请求专家进行标记。这些样本通常是那些模型对其预测不确定性较高的样本，或者是对模型性能提升有帮助的样本。通过重复这个过程，模型可以在有限的标记数据下取得更好的性能，相比于传统的随机选择样本进行标记，主动学习可以更高效地利用有限的标记资源。
##### 1.2 为什么需要主动学习？
主动学习的出现是为了解决以下问题：

1. 标记数据成本高昂：在许多情况下，获取和标记数据是非常昂贵的，例如医学图像、语音识别等领域。通过主动学习，可以最大程度地减少需要标记的数据量，从而降低标记数据的成本。

2. 数据不平衡：在某些情况下，数据分布可能不平衡，导致模型在一些类别上性能较差。主动学习可以帮助模型更好地学习少数类别的样本，从而提高整体性能。

3. 数据获取困难：有时候获取标记数据可能非常困难，例如在一些特定的领域或者在特定的地区。通过主动学习，可以更有效地利用已有的标记数据，从而减少对新数据的依赖。

因此，主动学习的出现可以帮助提高模型的性能，降低标记数据的成本，解决数据不平衡问题，以及处理数据获取困难的情况。
### 二、主动学习篇
##### 2.1 主动学习的思路是什么？
主动学习是一种机器学习的方法，其思路是让模型能够主动选择最有益于提高性能的数据进行标记和学习。主动学习的思路可以概括为以下几个步骤：

1. 初始阶段：模型使用少量标记数据进行训练，通常是一些随机选择的样本。

2. 不确定性采样：模型对未标记的数据进行预测，并选择模型认为最不确定的样本进行标记。这些样本可能是模型预测概率最接近50%的样本，或者是模型对不同类别预测概率相差不大的样本。

3. 标记数据：选定的不确定性样本被标记，加入到已标记数据中。

4. 重新训练：使用新增的标记数据重新训练模型。

5. 重复迭代：重复进行不确定性采样、标记数据和重新训练的过程，直到模型性能收敛或达到满意的水平。

通过主动学习的思路，模型可以在有限的标记数据下取得更好的性能，因为它能够选择最具信息量的样本进行学习，从而更有效地利用标记数据。这种方法在数据标记成本高昂、数据不平衡或数据获取困难的情况下尤为有用。
##### 2.2 主动学习方法 的价值点在哪里？
主动学习方法的价值点在于能够有效地利用有限的标记数据来训练模型，并在模型性能方面提供了一些重要的优势：

1. 数据高效利用：主动学习能够选择最具信息量的样本进行标记，从而最大限度地提高模型性能，减少了需要标记的数据量，节省了标记数据的成本和时间。

2. 模型性能改善：通过选择最不确定的样本进行标记，主动学习可以帮助模型更快地收敛到较高的性能水平，尤其在初始阶段的模型性能提升明显。

3. 处理数据不平衡：在数据集中存在类别不平衡的情况下，主动学习可以帮助模型更好地学习少数类别的样本，从而提高模型对少数类别的识别能力。

4. 适用于大规模数据：在大规模数据集的情况下，标记所有数据可能是不现实的，主动学习可以帮助选择最具代表性的样本进行标记，从而更高效地处理大规模数据。

总的来说，主动学习方法能够在有限的标记数据下提高模型性能，节省标记数据成本，适应数据不平衡和大规模数据等问题，因此在实际应用中具有重要的价值。
### 三、样本选取策略篇
##### 3.1 以未标记样本的获取方式的差别进行划分
在主动学习中，样本选取策略可以根据未标记样本的获取方式进行划分。以下是一些常见的样本选取策略：

1. 不确定性采样：该策略通过使用模型的预测不确定性来选择未标记样本。通常情况下，模型对于某些样本的预测会更加不确定，因此选择这些样本进行标记可以带来更多的信息收益。

2. 边界采样：该策略选择靠近类别边界的未标记样本进行标记。这些样本通常更具有代表性，可以帮助模型更好地区分不同类别。

3. 多样性采样：该策略通过选择与已标记样本最不相似的未标记样本来进行标记。这样可以确保模型在学习过程中能够涵盖更多的不同情况和特征，提高泛化能力。

4. 模型不确定性采样：该策略结合了不确定性采样和模型的置信度来选择未标记样本。通过综合考虑模型的不确定性和置信度，可以更加准确地选择具有信息量的样本进行标记。

这些样本选取策略可以根据未标记样本的获取方式的差别进行划分，选择适合特定任务和数据集的策略进行样本选取，从而提高主动学习的效果。
##### 3.2 测试集内选取“信息”量最大的数据标记
###### 3.2.1 测试集内选取“信息”量最大的数据标记
在主动学习中，测试集通常用于评估模型的性能，而不是用于选取样本进行标记。主动学习的核心思想是在训练过程中选择最具信息量的样本进行标记，以提高模型性能。因此，通常不会在测试集内选取“信息”量最大的数据进行标记。

如果您想要在测试集中选取最具信息量的数据进行标记，可能需要重新考虑问题的设定。通常情况下，主动学习的样本选取策略是在训练集上进行的，通过模型的预测不确定性、边界样本、多样性等方式来选择未标记样本进行标记。测试集则用于评估模型的泛化性能，而不是用于主动选择样本进行标记。
###### 3.2.2 依赖不确定度的样本选取策略（Uncertainty Sampling, US）
依赖不确定度的样本选取策略（Uncertainty Sampling, US）是主动学习中常用的一种样本选取策略。该策略基于模型的预测不确定度来选择最具信息量的未标记样本进行标记，以帮助模型更好地学习并提高性能。

Uncertainty Sampling通常包括以下几种常见的样本选取方法：

1. 最大化概率（Maximum Probability）：选择模型对某一类别预测概率最大的样本进行标记。这种方法假设模型对于预测概率最大的样本更加确信，因此选择这些样本进行标记可以减少模型的不确定性。

2. 最小化概率（Minimum Probability）：选择模型对某一类别预测概率最小的样本进行标记。这种方法假设模型对于预测概率最小的样本更加不确定，因此选择这些样本进行标记可以带来更多的信息量。

3. 最大化熵（Maximum Entropy）：选择模型预测概率分布的熵最大的样本进行标记。熵是对模型预测的不确定性的度量，选择熵最大的样本进行标记可以带来更多的信息量。

通过依赖不确定度的样本选取策略，可以有效地选择最具信息量的未标记样本进行标记，从而帮助模型更好地学习和泛化。这些方法可以在不同的主动学习任务中发挥作用，提高模型的性能。
###### 3.2.3 基于委员会查询的方法（Query-By-Committee，QBC）
基于委员会查询的方法（Query-By-Committee，QBC）是主动学习中常用的一种样本选取策略。在这种方法中，使用多个模型来构建一个委员会（committee），然后根据这些模型的不同预测结果来选择最具争议性的样本进行标记。

QBC方法的基本思想是，当委员会中的模型对某个样本的预测结果存在较大差异时，这个样本很可能是一个不确定的样本，选择这样的样本进行标记可以提供更多的信息量。QBC方法的具体步骤如下：

1. 训练多个不同的模型，可以使用不同的算法、不同的初始化参数或者不同的训练数据子集来训练这些模型，以确保它们有一定的差异性。

2. 对于未标记的样本，使用委员会中的每个模型进行预测。

3. 根据这些模型的预测结果，计算样本的预测差异性或者争议性，通常使用不确定性度量（如熵、方差等）来衡量。

4. 选择预测差异性或争议性最大的样本进行标记，以提供更多信息给模型。

通过使用QBC方法，可以利用多个模型之间的差异性来选择最具争议性的样本进行标记，从而帮助模型更好地学习和泛化。这种方法在主动学习中被广泛应用，并且通常能够取得良好的效果。